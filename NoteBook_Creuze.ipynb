{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "def scrape_afcae_total():\n",
    "    scraper = cloudscraper.create_scraper(\n",
    "        browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}\n",
    "    )\n",
    "    all_films = []\n",
    "    total_pages = 355 \n",
    "\n",
    "\n",
    "    for page in range(0, total_pages):\n",
    "        url = f\"https://www.art-et-essai.org/les-films-recommandes?page={page}\"\n",
    "        \n",
    "        try:\n",
    "            # Tentative de rÃ©cupÃ©ration\n",
    "            response = scraper.get(url, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                table_body = soup.find('tbody')\n",
    "                rows = table_body.find_all('tr')\n",
    "                for row in rows:\n",
    "                    # Extraction des colonnes\n",
    "                    titre = row.find('td', class_='views-field-title')\n",
    "                    directeur = row.find('td', class_='views-field-field-director-text')\n",
    "                    date = row.find('td', class_='views-field-field-release-date')\n",
    "                    distrib = row.find('td', class_='views-field-field-distributeur-text')\n",
    "                    label = row.find('td', class_='views-field-field-label')\n",
    "                    visa = row.find('td', class_='views-field-field-visa')\n",
    "\n",
    "                    all_films.append({\n",
    "                        'Titre': titre.get_text(strip=True) if titre else \"N/A\",\n",
    "                        'RÃ©alisateur': directeur.get_text(strip=True) if directeur else \"N/A\",\n",
    "                        'Date_Sortie': date.get_text(strip=True) if date else \"N/A\",\n",
    "                        'Distributeur': distrib.get_text(strip=True) if distrib else \"N/A\",\n",
    "                        'Label': label.get_text(strip=True) if label else \"N/A\",\n",
    "                        'VISA': visa.get_text(strip=True) if visa else \"N/A\",\n",
    "                        'Source_Page': page\n",
    "                    })\n",
    "                \n",
    "                # Feedback de progression\n",
    "                if page % 10 == 0:\n",
    "                    print(f\"ðŸš€ Progression : Page {page}/{total_pages} | {len(all_films)} films collectÃ©s...\")\n",
    "\n",
    "                # Sauvegarde intermÃ©diaire toutes les 50 pages au cas oÃ¹\n",
    "                if page % 50 == 0 and page > 0:\n",
    "                    temp_df = pd.DataFrame(all_films)\n",
    "                    temp_df.to_csv(f\"backup_page_{page}.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "            elif response.status_code == 403:\n",
    "                print(f\"BloquÃ© par le serveur Ã  la page {page}. Pause de 30 secondes...\")\n",
    "                time.sleep(30)\n",
    "                continue # On rÃ©essaie la mÃªme page\n",
    "                \n",
    "            else:\n",
    "                print(f\"Erreur HTTP {response.status_code} Ã  la page {page}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur Ã  la page {page}: {str(e)}\")\n",
    "            # Sauvegarde d'urgence en cas d'erreur\n",
    "            if all_films:\n",
    "                emergency_df = pd.DataFrame(all_films)\n",
    "                emergency_df.to_csv(f\"emergency_save_page_{page}.csv\", index=False, encoding='utf-8-sig')\n",
    "            continue\n",
    "        \n",
    "        # Pause alÃ©atoire pour Ã©viter de surcharger le serveur\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    # Export final\n",
    "    \n",
    "    if all_films:\n",
    "        df_final = pd.DataFrame(all_films)\n",
    "        \n",
    "        # Nettoyage des doublons potentiels\n",
    "        df_final = df_final.drop_duplicates(subset=['Titre', 'VISA'], keep='first')\n",
    "        \n",
    "        # Export CSV final\n",
    "        output_file = \"films_afcae_complet.csv\"\n",
    "        df_final.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "  \n",
    "        return df_final\n",
    "  \n",
    "\n",
    "# Lancement du scraping\n",
    "if __name__ == \"__main__\":\n",
    "    df_films = scrape_afcae_total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On check les la database\n",
    "df_films.shape\n",
    "df_films.info()\n",
    "df_films.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b47cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer\n",
    "YEAR_MIN = 1950  # Films depuis 1950\n",
    "BLOCKBUSTER_VOTE_THRESHOLD = 2000  # Seuil pour blockbusters US\n",
    "\n",
    "#Importer fichier TMDB\n",
    "id_drive = '1VB5_gl1fnyBDzcIOXZ5vUSbCY68VZN1v'\n",
    "output_tmdb = 'tmdb_final.csv'\n",
    "url_drive = f'https://drive.google.com/uc?id={id_drive}'\n",
    "\n",
    "#tÃ©lÃ©chargement de la base de donnÃ©e\n",
    "gdown.download(url_drive, output_tmdb, quiet=False)\n",
    "\n",
    "df_tmdb = pd.read_csv(output_tmdb)\n",
    "\n",
    "\n",
    "# NETTOYAGE JSON\n",
    "\n",
    "def clean_json(x):\n",
    "    try:\n",
    "        if pd.isna(x): return np.nan\n",
    "        data = json.loads(x.replace(\"'\", '\"'))\n",
    "        return \", \".join([i['name'] for i in data])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if 'production_companies' in df_tmdb.columns:\n",
    "    df_tmdb['companies_clean'] = df_tmdb['production_companies'].apply(clean_json)\n",
    "\n",
    "# GARDE production_countries et le nettoie\n",
    "if 'production_countries' in df_tmdb.columns:\n",
    "    df_tmdb['countries_clean'] = df_tmdb['production_countries'].apply(clean_json)\n",
    "\n",
    "# Suppression colonnes inutiles (GARDE production_countries)\n",
    "cols_drop = ['homepage', 'video', 'backdrop_path', 'status', 'production_companies']\n",
    "df_tmdb = df_tmdb.drop(columns=[c for c in cols_drop if c in df_tmdb.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c748d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIE IMDB \n",
    "# IMDB BASIC\n",
    "\n",
    "print(f\"\\nðŸ“¥ IMDb Basics : SÃ©lection (>= {YEAR_MIN})...\")\n",
    "url_basics = \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "chunks_basics = []\n",
    "\n",
    "if 'imdb_id' in df_tmdb.columns:\n",
    "    ids_tmdb = set(df_tmdb['imdb_id'].dropna())\n",
    "else:\n",
    "    ids_tmdb = set()\n",
    "\n",
    "with pd.read_csv(url_basics, sep='\\t', compression='gzip',\n",
    "                 usecols=['tconst', 'titleType', 'startYear', 'primaryTitle', 'genres', 'runtimeMinutes'],\n",
    "                 chunksize=500000) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk['startYear'] = pd.to_numeric(chunk['startYear'], errors='coerce')\n",
    "        \n",
    "        mask = (\n",
    "            (chunk['titleType'] == 'movie') &\n",
    "            (chunk['startYear'] >= YEAR_MIN) &\n",
    "            (chunk['tconst'].isin(ids_tmdb))\n",
    "        )\n",
    "        \n",
    "        filtered_chunk = chunk[mask]\n",
    "        \n",
    "        if not filtered_chunk.empty:\n",
    "            chunks_basics.append(filtered_chunk[['tconst', 'primaryTitle', 'startYear', 'genres', 'runtimeMinutes']])\n",
    "\n",
    "df_basics = pd.concat(chunks_basics, ignore_index=True)\n",
    "print(f\"   âœ… Films retenus ({YEAR_MIN}-2025) : {len(df_basics):,}\")\n",
    "\n",
    "ids_films_finaux = set(df_basics['tconst'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ecafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb NAME.BASICS (Noms des personnes)\n",
    "\n",
    "print(\"\\nðŸ“¥ IMDb name.basics : Chargement des noms...\")\n",
    "url_names = \"https://datasets.imdbws.com/name.basics.tsv.gz\"\n",
    "\n",
    "# Charge toute la base (peut prendre 5-10 min)\n",
    "df_names = pd.read_csv(url_names, sep='\\t', compression='gzip', low_memory=False)\n",
    "print(f\"   âœ… {len(df_names):,} personnes chargÃ©es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb PRINCIPALS (Directors, Actors, Actresses)\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“¥ IMDb title.principals : Extraction du cast & crew...\")\n",
    "url_principals = \"https://datasets.imdbws.com/title.principals.tsv.gz\"\n",
    "\n",
    "chunks_directors = []\n",
    "chunks_actors = []\n",
    "chunks_actresses = []\n",
    "chunk_count = 0\n",
    "\n",
    "with pd.read_csv(url_principals, sep='\\t', compression='gzip',\n",
    "                 usecols=['tconst', 'ordering', 'nconst', 'category', 'characters'],\n",
    "                 chunksize=500000) as reader:\n",
    "    \n",
    "    for chunk in reader:\n",
    "        chunk_count += 1\n",
    "        if chunk_count % 5 == 0:\n",
    "            print(f\"   ðŸ“¦ Chunk {chunk_count}...\")\n",
    "        \n",
    "        mask = chunk['tconst'].isin(ids_films_finaux)\n",
    "        chunk_filtered = chunk[mask]\n",
    "        \n",
    "        if chunk_filtered.empty:\n",
    "            continue\n",
    "        \n",
    "        # REALISATEURS\n",
    "        directors = chunk_filtered[chunk_filtered['category'] == 'director'][['tconst', 'nconst']]\n",
    "        if not directors.empty:\n",
    "            chunks_directors.append(directors)\n",
    "        \n",
    "        # ACTEURS\n",
    "        actors = chunk_filtered[chunk_filtered['category'] == 'actor'][['tconst', 'ordering', 'nconst', 'characters']]\n",
    "        if not actors.empty:\n",
    "            chunks_actors.append(actors)\n",
    "        \n",
    "        # ACTRICES\n",
    "        actresses = chunk_filtered[chunk_filtered['category'] == 'actress'][['tconst', 'ordering', 'nconst', 'characters']]\n",
    "        if not actresses.empty:\n",
    "            chunks_actresses.append(actresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1df517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAITEMENT REALISATEUR\n",
    "if chunks_directors:\n",
    "    print(\"\\nðŸ‘¨â€ðŸŽ¬ Traitement des rÃ©alisateurs...\")\n",
    "    df_directors = pd.concat(chunks_directors, ignore_index=True)\n",
    "    df_directors = df_directors.drop_duplicates(subset='tconst', keep='first')\n",
    "    \n",
    "    # Merge avec les noms\n",
    "    df_directors = df_directors.merge(\n",
    "        df_names[['nconst', 'primaryName', 'birthYear']],\n",
    "        on='nconst',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    df_directors.rename(columns={\n",
    "        'nconst': 'director_id',\n",
    "        'primaryName': 'director_name',\n",
    "        'birthYear': 'director_birth'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Ajoute Ã  df_basics\n",
    "    df_basics = df_basics.merge(\n",
    "        df_directors[['tconst', 'director_id', 'director_name', 'director_birth']],\n",
    "        on='tconst',\n",
    "        how='left'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAITEMENT ACTREURS\n",
    "if chunks_actors:\n",
    "    df_actors = pd.concat(chunks_actors, ignore_index=True)\n",
    "    df_actors = df_actors.sort_values(['tconst', 'ordering']).groupby('tconst').head(5)\n",
    "    \n",
    "    df_actors = df_actors.merge(\n",
    "        df_names[['nconst', 'primaryName']],\n",
    "        on='nconst',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    actors_agg = df_actors.groupby('tconst').agg({\n",
    "        'nconst': lambda x: '|'.join(x.astype(str)),\n",
    "        'primaryName': lambda x: '|'.join(x.dropna().astype(str))\n",
    "    }).reset_index()\n",
    "    \n",
    "    actors_agg.rename(columns={\n",
    "        'nconst': 'actors_ids',\n",
    "        'primaryName': 'actors_names'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    df_basics = df_basics.merge(actors_agg, on='tconst', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fde963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAITEMENT ACTRICES\n",
    "if chunks_actresses:\n",
    "    df_actresses = pd.concat(chunks_actresses, ignore_index=True)\n",
    "    df_actresses = df_actresses.sort_values(['tconst', 'ordering']).groupby('tconst').head(5)\n",
    "    \n",
    "    df_actresses = df_actresses.merge(\n",
    "        df_names[['nconst', 'primaryName']],\n",
    "        on='nconst',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    actresses_agg = df_actresses.groupby('tconst').agg({\n",
    "        'nconst': lambda x: '|'.join(x.astype(str)),\n",
    "        'primaryName': lambda x: '|'.join(x.dropna().astype(str))\n",
    "    }).reset_index()\n",
    "    \n",
    "    actresses_agg.rename(columns={\n",
    "        'nconst': 'actresses_ids',\n",
    "        'primaryName': 'actresses_names'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    df_basics = df_basics.merge(actresses_agg, on='tconst', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUSION FINALE AVEC TMDB\n",
    "df_final = pd.merge(df_basics, df_tmdb, left_on='tconst', right_on='imdb_id', how='inner')\n",
    "df_final = df_final.drop(columns=['imdb_id'], errors='ignore')\n",
    "\n",
    "# Nettoie et combine la durÃ©e\n",
    "df_final['runtimeMinutes'] = pd.to_numeric(df_final['runtimeMinutes'], errors='coerce')\n",
    "if 'runtime' in df_final.columns:\n",
    "    df_final['runtime'] = pd.to_numeric(df_final['runtime'], errors='coerce')\n",
    "    df_final['duration'] = df_final['runtime'].fillna(df_final['runtimeMinutes'])\n",
    "else:\n",
    "    df_final['duration'] = df_final['runtimeMinutes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRAGE PAR CATÃ‰GORIE : ComÃ©dies FR + Blockbusters US\n",
    "\n",
    "# COMÃ‰DIES FRANÃ‡AISES\n",
    "mask_comedies_fr = (\n",
    "    df_final['production_companies_country'].str.contains('FR', na=False, case=False) &\n",
    "    df_final['genres_x'].str.contains('Comedy', na=False, case=False)\n",
    ")\n",
    "df_comedies_fr = df_final[mask_comedies_fr].copy()\n",
    "df_comedies_fr['category'] = 'ComÃ©die FranÃ§aise'\n",
    "\n",
    "# BLOCKBUSTERS AMÃ‰RICAINS\n",
    "mask_blockbusters_us = (\n",
    "    df_final['production_companies_country'].str.contains('US', na=False, case=False) &\n",
    "    (df_final['vote_count'] >= BLOCKBUSTER_VOTE_THRESHOLD)\n",
    ")\n",
    "df_blockbusters_us = df_final[mask_blockbusters_us].copy()\n",
    "df_blockbusters_us['category'] = 'Blockbuster AmÃ©ricain'\n",
    "\n",
    "# Combine les deux catÃ©gories\n",
    "df_final_filtered = pd.concat([df_comedies_fr, df_blockbusters_us], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "\n",
    "# Export principal (tous les films)\n",
    "df_final.to_csv(\"Dataset_1960_Plus.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Export filtrÃ© (comÃ©dies FR + blockbusters US)\n",
    "df_final_filtered.to_csv(\"Database_Comedies_FR_Blockbusters_US.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Exports sÃ©parÃ©s\n",
    "df_comedies_fr.to_csv(\"Database_Comedies_Francaises.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "df_blockbusters_us.to_csv(\"Database_Blockbusters_Americains.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7077dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les databases\n",
    "\n",
    "df_tt = pd.read_csv(r\"C:\\Users\\Consultant\\Desktop\\creuze_project\\Dataset_1960_Plus.csv\")\n",
    "df_afcae = pd.read_csv(r\"C:\\Users\\Consultant\\Desktop\\creuze_project\\films_afcae_complet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_director_name(name):\n",
    "    if pd.isna(name) or name == \"\":\n",
    "        return name\n",
    "    \n",
    "    parts = str(name).split()\n",
    "    if len(parts) >= 2:\n",
    "        # On suppose que le premier mot est le NOM (ex: TAN) \n",
    "        # et le reste le PrÃ©nom (ex: Royston)\n",
    "        nom = parts[0].capitalize()\n",
    "        prenom = \" \".join(parts[1:]).title()\n",
    "        return f\"{prenom} {nom}\"\n",
    "    return str(name).title()\n",
    "\n",
    "# Application sur ta database\n",
    "df_afcae['director_clean'] = df_afcae['RÃ©alisateur'].apply(fix_director_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_names(name):\n",
    "    if pd.isna(name): return \"\"\n",
    "    # On met en minuscule, on enlÃ¨ve les accents et on sÃ©pare les mots\n",
    "    parts = str(name).lower().strip().split()\n",
    "    # On trie les mots par ordre alphabÃ©tique : ['royston', 'tan'] ou ['tan', 'royston'] deviennent identiques\n",
    "    parts.sort()\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# Creation d'une colonne avec les noms normalisÃ©s\n",
    "df_afcae['dir_key'] = df_afcae['RÃ©alisateur'].apply(normalize_names)\n",
    "df_tt['dir_key'] = df_tt['director_name'].apply(normalize_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour AFCAE : on convertit et on gÃ¨re les erreurs\n",
    "df_afcae['release_date'] = pd.to_datetime(df_afcae['Date_Sortie'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Pour TMDB\n",
    "df_tt['release_date'] = pd.to_datetime(df_tt['release_date'], errors='coerce')\n",
    "\n",
    "# On le remet au format texte, mais version TMDB (1962-06-22)\n",
    "df_afcae['release_date'] = df_afcae['release_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# --- 2. HARMONISATION DES TITRES ---\n",
    "# On met tout en minuscules (.str.lower()) et on enlÃ¨ve les espaces inutiles (.str.strip())\n",
    "df_afcae['titre_key'] = df_afcae['Titre'].str.capitalize().str.strip()\n",
    "df_tt['titre_key'] = df_tt['original_title'].str.capitalize().str.strip()\n",
    "\n",
    "# Harmonisation des titres (Minuscules + Nettoyage)\n",
    "df_afcae['titre_key'] = df_afcae['Titre'].str.lower().str.strip()\n",
    "df_tt['titre_key'] = df_tt['original_title'].str.lower().str.strip()\n",
    "\n",
    "# Harmonisation des dates (AnnÃ©e uniquement)\n",
    "# On extrait l'annÃ©e car le jour prÃ©cis peut varier d'une base Ã  l'autre\n",
    "df_afcae['year_key'] = pd.to_datetime(df_afcae['Date_Sortie'], dayfirst=True, errors='coerce').dt.year\n",
    "df_tt['year_key'] = pd.to_datetime(df_tt['release_date'], errors='coerce').dt.year\n",
    "\n",
    "# Harmonisation des rÃ©alisateurs\n",
    "df_afcae['dir_key'] = df_afcae['director_clean'].str.lower().str.strip()\n",
    "df_tt['dir_key'] = df_tt['director_name'].str.lower().str.strip()\n",
    "\n",
    "# Comparer et rendre chaque caractere similaire\n",
    "df_tt['dir_key'] = df_tt['director_name'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_afcae['dir_key'] = df_afcae['director_clean'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_tt['titre_key'] = df_tt['original_title'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_afcae['titre_key'] = df_afcae['Titre'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rassembler toutes les databases\n",
    "df_art_final = pd.merge(\n",
    "    df_afcae, \n",
    "    df_tt, \n",
    "    left_on=['titre_key', 'dir_key'],\n",
    "    right_on=['titre_key', 'dir_key'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "\n",
    "#Nettoyage\n",
    "#SÃ©lectionner les films suppÃ©rieur Ã  60 minutes\n",
    "art_essai = df_art_final[(df_art_final['runtime'] >= 60) | (df_art_final['runtime'].isna())]\n",
    "\n",
    "#ajouter les autres Databases\n",
    "df_reste = pd.read_csv(r\"C:\\Users\\Consultant\\Desktop\\creuze_project\\Database_Comedies_FR_Blockbusters_US.csv\")\n",
    "df_final_complet = pd.concat([art_essai, df_reste], axis=0, ignore_index=True)\n",
    "\n",
    "#Supprimer les colonnes inutiles\n",
    "cols_to_drop = [\n",
    "    'adult', 'budget', 'genres_y', 'release_date', 'title',\n",
    "    'production_companies_name', 'production_companies_country',\n",
    "    'countries_clean', 'tagline', 'runtimeMinutes', 'release_date_y', 'director_birth'\n",
    "]\n",
    "\n",
    "df_complet = df_final_complet.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Supprimer les doublons basÃ©s sur la colonne 'id'\n",
    "df_complet = df_complet.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "#VÃ©rifier Valeur manquante\n",
    "df_complet.isna().sum()\n",
    "\n",
    "#5 RÃ©alisateurs manquants\n",
    "df_complet[df_complet['director_name'].isna()]\n",
    "# On cible le film par son titre et on remplit le nom des rÃ©alisateurs\n",
    "df_complet.loc[df_complet['primaryTitle'] == 'Ugly Melanie', 'director_name'] = 'Allan Mauduit'\n",
    "df_complet.loc[df_complet['primaryTitle'] == 'The Shiny Shrimps', 'director_name'] = 'Mathias Le Goff'\n",
    "df_complet.loc[df_complet['primaryTitle'] == 'Fake News', 'director_name'] = 'Mouloud Achour|Dominique Baumard'\n",
    "df_complet.loc[df_complet['primaryTitle'] == 'The Adventures of Felix', 'director_name'] = \"Olivier Ducastel|Jacques Martineau\"\n",
    "df_complet.loc[df_complet['primaryTitle'] == \"CÃ´te d'Azur\", 'director_name'] = \"Olivier Ducastel|Jacques Martineau\"\n",
    "\n",
    "#remplacer valeur manquante dans CatÃ©gorie \n",
    "df_complet['category']= df_complet['category'].fillna('Art et Essai')\n",
    "\n",
    "#remplacer valeur manquante dans le casting\n",
    "cols = ['actors_ids', 'actors_names', 'actresses_ids', 'actresses_names']\n",
    "df_complet[cols] = df_complet[cols].fillna('UNKNOWN')\n",
    "df_complet['director_id'] = df_complet['director_id'].fillna('UNKNOWN')\n",
    "\n",
    "#remplacer les synopsis manquants par inconnu\n",
    "df_complet['overview'] = df_complet['overview'].fillna('UNKNOWN')\n",
    "\n",
    "#remplacer les valeurs manquantes des affiches\n",
    "df_complet['poster_path'] = df_complet['poster_path'].fillna('UNKNOWN')\n",
    "\n",
    "#remplacer les valeurs manquantes des Distributeurs\n",
    "df_complet['Distributeur'] = df_complet['Distributeur'].fillna('UNKNOWN')\n",
    "\n",
    "#Retirer les colonnes en trop pour les statistiques\n",
    "\n",
    "cols_to_drop = [\n",
    "    'director_id','actors_ids', 'actresses_ids', 'id', 'spoken_languages', 'revenue',\n",
    "    'production_countries', 'poster_path'\n",
    "]\n",
    "\n",
    "df_stat = df_complet.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "#changement des noms des colonnes\n",
    "df_copy = df_complet.copy()\n",
    "df_copy = df_copy.rename(columns={'startYear': 'AnnÃ©e_de_Sortie',\n",
    "                       'genres_x': 'Genre',\n",
    "                       'director_id': 'RÃ©alisateur_id',\n",
    "                       'director_name' : 'RÃ©alisateur',\n",
    "                       'actors_ids': 'Acteur_Id',\n",
    "                       'actors_names': 'Acteur',\n",
    "                       'actresses_ids': 'Actrice_Id',\n",
    "                       'actresses_names': 'Actrice',\n",
    "                       'id': 'Id_film', \n",
    "                       'spoken_languages': 'VO',\n",
    "                       'original_title' : 'Titre',\n",
    "                       'overview': 'Synopsis',\n",
    "                       'popularity': 'PopularitÃ©',\n",
    "                       'revenue': 'Revenues',\n",
    "                       'runtime': 'DurÃ©e',\n",
    "                       'spoken_languages': 'Langues',\n",
    "                       'vote_average': 'Note',\n",
    "                       'vote_count': 'Nombre_de_Vote',\n",
    "                       'production_countries': 'Pays', \n",
    "                       'poster_path': 'Affiche_de_Film' ,\n",
    "                       'category': 'CatÃ©gorie'\n",
    "                       },\n",
    "               inplace=False)\n",
    "\n",
    "cols_to_drop = [\n",
    "    'primaryTitle','duration'\n",
    "]\n",
    "\n",
    "df= df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "df = df[df['DurÃ©e'] >= 60]\n",
    "df.to_csv('Database_finale.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
